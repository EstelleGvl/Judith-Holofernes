 ---
title: "Notes 11: Your Own Data"
output: html_document
---

```{r setup, include=FALSE, warning=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = FALSE)

library(readr)
library(dplyr)
library(ggplot2)
library(stringi)
library(jpeg)

source(file.path("scripts", "funs.R"))
```

# Your own dataset 

These notes show you how to use these notes with your own data. The notebook works by
default on the images put in the directory named "test". We put a few images in here 
to start, but you can add more to the directory and re-run this notebook. If you modify
the name of the file in the code below, you can replicate for a dataset with your own
choosen name by just changing the following line of code to the dataset name that you
would like to use. 

```{r}
cn <- "test"
```

The first thing that we need to do is find all of the images in the test directory. Our
test dataset contains 50 images of fruits:

```{r}
head(dir(file.path("images", cn)))
```


# Images with no metadata (i.e. csv file)

We will make a dataset from these paths:

```{r}
mydata <- tibble(path = dir(file.path("images", cn)))
mydata
```

```{r}
path <- file.path("data", sprintf("%s.csv", cn))
if (!file.exists(path)) {
  write_csv(mydata, path)
}
```

# Images with metadata (i.e. a .csv file)

Let's say I already have a .csv file for my images. Make sure there is a column called "path". This should be the file names for your images. We can load that in.

```{r}
mydata <- read_csv(file.path("data", sprintf("%s.csv", cn)))
```


# Adding Color Data

And then start to fill in the various metrics that we used throughout the lessons.
Start by creating each of the variables:

```{r}
mydata$avg_red    <- 0
mydata$avg_orange <- 0
mydata$avg_yellow <- 0
mydata$avg_green  <- 0
mydata$avg_blue   <- 0
mydata$avg_violet <- 0
mydata$avg_black  <- 0
mydata$avg_grey   <- 0
mydata$avg_white  <- 0
mydata$avg_saturation <- 0
mydata$avg_value      <- 0
```

And then cycle through the images. Because this can take a long time with larger datasets,
we wrote a line of code to let us know everytime it has processed 10 new images

```{r}
for (i in seq_len(nrow(mydata)))
{
  img <- readJPEG(file.path("images", cn, mydata$path[i]))
  hsv <- rgb2hsv(as.numeric(img[,,1]), as.numeric(img[,,2]), as.numeric(img[,,3]), maxColorValue = 1)
  index <- which((hsv[2,] > 0.3) & (hsv[3,] > 0.3))
  if (length(index))
  {
    mydata$avg_red[i]    <- sum(hsv[1,index] < 0.075 | hsv[1,index] > 0.861) / prod(dim(img))
    mydata$avg_orange[i] <- sum(between(hsv[1,index], 0.075, 0.122)) / prod(dim(img))
    mydata$avg_yellow[i] <- sum(between(hsv[1,index], 0.122, 0.194)) / prod(dim(img))
    mydata$avg_green[i]  <- sum(between(hsv[1,index], 0.194, 0.464)) / prod(dim(img))
    mydata$avg_blue[i]   <- sum(between(hsv[1,index], 0.464, 0.708)) / prod(dim(img))
    mydata$avg_violet[i] <- sum(between(hsv[1,index], 0.708, 0.861)) / prod(dim(img))
  }

  index <- which((hsv[2,] <= 0.3) | (hsv[3,] <= 0.3))
  if (length(index))
  {
    mydata$avg_black[i]  <- sum(hsv[3,] < 0.25) / prod(dim(img))
    mydata$avg_grey[i]   <- sum(between(hsv[3,], 0.25, 0.8)) / prod(dim(img))
    mydata$avg_white[i]  <- sum(hsv[3,] > 0.8)  / prod(dim(img))
  }

  mydata$avg_saturation[i] <- mean(hsv[2,hsv[3,] > 0.3])
  mydata$avg_value[i] <- mean(img)

  if ((i %% 10) == 0) print(sprintf("Done with %d of %d", i, nrow(mydata)))
}

```

And now we should have our dataset:

```{r}
mydata
```

And now we can do all of the kinds of analysis that we previously performed, such as finding
the most "red" fruits:

```{r}
show_image(file.path("images", cn, top_n(mydata, avg_red, n=6)$path), ncol=3)
```

We can also save the dataset as a csv file in our directory so that we can run analyses without having
to create the dataset each time.

```{r}
write_csv(mydata, file.path("data", sprintf("%s.csv", cn)))
```

And that's it for all of the "shallow" features. Feel free to make your own dataset by putting images
into a directory and changing the variable `cn` to match the new name.

# Deep Learning

Running the neural network models requires some additional setup. The actual code is straightforward,
but the setup process can be challenging, particularly on a Windows machine. The first step is to 
install the keras R package with the following (this should not cause any major problems).

```{r}
if (!require("keras")) install.packages("keras", repos = "https://cran.rstudio.com/")
```

The next, more involved step, is to install Python3 and the Python library called Keras. You should
do this by first installing Anaconda Python version 3.7 (or higher) from here:

    https://www.anaconda.com/distribution/#download-section
    
Then, you need to install two Python packages. You can do this by either following the instructions
from the R-side:

    https://keras.rstudio.com/

Or the instructions for installing the Python-side:

    https://keras.io/#installation
    
The first option should be the easiest approach in theory, but we have found that 
has a relatively low-success rate in practice. The second approach requires understanding a bit more about how Python works.

Once you have everything installed, load the keras library and set the following environmental
variable (it ignored a common warning the causes the system to crash on macOS):

```{r}
library(keras)

Sys.setenv(KMP_DUPLICATE_LIB_OK="TRUE")
```

Then, we load the pre-trained ResNet-50 model. This can take a bit of time, particularly the first
time on a slow connection because it needs to download a relatively large dataset. Just give it time,
it usually works eventually.

```{r}
resnet50 <- application_resnet50(weights = 'imagenet', include_top = TRUE)
model_avg_pool <- keras_model(inputs = resnet50$input,
                              outputs = get_layer(resnet50, 'avg_pool')$output)
```

Next, we load all of the images and pass them through a special preprocessing
function to standardize the distribution of the red, green, and blue pixel intensities to
match the data that the model was trained with. (Note: this approach work for a few thousand
images; after that, you'll need to process the dataset in batched. If that becomes a problem,
please let us know).

```{r}
data <- read_csv(file.path("data", sprintf("%s.csv", cn)), )
Z <- array(0, dim = c(length(data$path), 224, 224, 3))
for (i in seq_len(nrow(data)))
{
  pt <- file.path("images", cn, data$path[i])
  image <- image_to_array(image_load(pt, target_size = c(224,224)))
  Z[i,,,] <- array_reshape(image, c(1, dim(image)))
}
Z <- imagenet_preprocess_input(Z)
```

Now, embed each image into the avg_pool layer and save the results:

```{r}
X <- predict(model_avg_pool, x = Z, verbose = TRUE)
write_rds(X, file.path("models", sprintf("%s-pool.rds", cn)))
```

And finally, embed into the final layer and save results:

```{r}
X <- predict(resnet50, x = Z, verbose = TRUE)
preds <- Reduce(bind_rows, keras::imagenet_decode_predictions(X, top = 25))
preds$path <- rep(data$path, each = 25)
preds$rank <- rep(seq_len(25), nrow(data))
write_csv(preds, file.path("models", sprintf("%s-resnet50.csv", cn)))
```

You should have now created all of the same data we provided for the datasets included with this
tutorial. We can test out how well it works by loading the data back into R. Here, we see that it
was able to detect the limited number of fruits that are included in its training model (but mistakes
some other common fruits that are not in the 1000-categories):

```{r}
resnet <- read_csv(file.path("models", sprintf("%s-resnet50.csv", cn)))
filter(resnet, score > 0.9)
```

And here are the embeddings and nearest neighbors:

```{r}
embed <- read_rds(file.path("models", sprintf("%s-pool.rds", cn)))
dist_mat <- as.matrix(dist(embed))
nearest_img <- t(apply(dist_mat, 2, function(v) order(v)[seq(1, 6)]))
```

As with the image posters, the fruit images are not great because they are too small.
If you work with some larger images, you should be able to see the kinds of results 
we had with the WikiArt and FSA-OWI collections:

```{r}
start_img <- 1
show_image(file.path("images", cn, mydata$path[nearest_img[start_img,]]), ncol=3)
```

And remember, you can redo all of this on your own corpus by: (1) putting your images in a directory
inside of the images directory and (2) changing the name of the variable `cn` at the top of this notebook.
